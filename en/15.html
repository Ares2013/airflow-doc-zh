<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
<head><title></title>
<link href="../style/ebook.css" type="text/css" rel="stylesheet">
</head>
<body>
<h1>Scaling Out with Mesos (community contributed)</h1>
<p>There are two ways you can run airflow as a mesos framework:</p>
<ol class="arabic simple">
<li>Running airflow tasks directly on mesos slaves, requiring each mesos slave to have airflow installed and configured.</li>
<li>Running airflow tasks inside a docker container that has airflow installed, which is run on a mesos slave.</li>
</ol>
<div class="section" id="tasks-executed-directly-on-mesos-slaves">
<h2 class="sigil_not_in_toc">Tasks executed directly on mesos slaves</h2>
<p><code class="docutils literal notranslate"><span class="pre">MesosExecutor</span></code> allows you to schedule airflow tasks on a Mesos cluster.
For this to work, you need a running mesos cluster and you must perform the following
steps -</p>
<ol class="arabic simple">
<li>Install airflow on a mesos slave where web server and scheduler will run,
let&#x2019;s refer to this as the &#x201C;Airflow server&#x201D;.</li>
<li>On the Airflow server, install mesos python eggs from <a class="reference external" href="http://open.mesosphere.com/downloads/mesos/">mesos downloads</a>.</li>
<li>On the Airflow server, use a database (such as mysql) which can be accessed from all mesos
slaves and add configuration in <code class="docutils literal notranslate"><span class="pre">airflow.cfg</span></code>.</li>
<li>Change your <code class="docutils literal notranslate"><span class="pre">airflow.cfg</span></code> to point executor parameter to
<cite>MesosExecutor</cite> and provide related Mesos settings.</li>
<li>On all mesos slaves, install airflow. Copy the <code class="docutils literal notranslate"><span class="pre">airflow.cfg</span></code> from
Airflow server (so that it uses same sql alchemy connection).</li>
<li>On all mesos slaves, run the following for serving logs:</li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>airflow serve_logs
</pre>
</div>
</div>
<ol class="arabic simple" start="7">
<li>On Airflow server, to start processing/scheduling DAGs on mesos, run:</li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>airflow scheduler -p
</pre>
</div>
</div>
<p>Note: We need -p parameter to pickle the DAGs.</p>
<p>You can now see the airflow framework and corresponding tasks in mesos UI.
The logs for airflow tasks can be seen in airflow UI as usual.</p>
<p>For more information about mesos, refer to <a class="reference external" href="http://mesos.apache.org/documentation/latest/">mesos documentation</a>.
For any queries/bugs on <cite>MesosExecutor</cite>, please contact <a class="reference external" href="https://github.com/kapil-malik">@kapil-malik</a>.</p>
</div>
<div class="section" id="tasks-executed-in-containers-on-mesos-slaves">
<h2 class="sigil_not_in_toc">Tasks executed in containers on mesos slaves</h2>
<p><a class="reference external" href="https://gist.github.com/sebradloff/f158874e615bda0005c6f4577b20036e">This gist</a> contains all files and configuration changes necessary to achieve the following:</p>
<ol class="arabic simple">
<li>Create a dockerized version of airflow with mesos python eggs installed.</li>
</ol>
<blockquote>
<div>We recommend taking advantage of docker&#x2019;s multi stage builds in order to achieve this. We have one Dockerfile that defines building a specific version of mesos from source (Dockerfile-mesos), in order to create the python eggs. In the airflow Dockerfile (Dockerfile-airflow) we copy the python eggs from the mesos image.</div>
</blockquote>
<ol class="arabic simple" start="2">
<li>Create a mesos configuration block within the <code class="docutils literal notranslate"><span class="pre">airflow.cfg</span></code>.</li>
</ol>
<blockquote>
<div>The configuration block remains the same as the default airflow configuration (default_airflow.cfg), but has the addition of an option <code class="docutils literal notranslate"><span class="pre">docker_image_slave</span></code>. This should be set to the name of the image you would like mesos to use when running airflow tasks. Make sure you have the proper configuration of the DNS record for your mesos master and any sort of authorization if any exists.</div>
</blockquote>
<ol class="arabic simple" start="3">
<li>Change your <code class="docutils literal notranslate"><span class="pre">airflow.cfg</span></code> to point the executor parameter to
<cite>MesosExecutor</cite> (<cite>executor = SequentialExecutor</cite>).</li>
<li>Make sure your mesos slave has access to the docker repository you are using for your <code class="docutils literal notranslate"><span class="pre">docker_image_slave</span></code>.</li>
</ol>
<blockquote>
<div><a class="reference external" href="https://mesos.readthedocs.io/en/latest/docker-containerizer/#private-docker-repository">Instructions are available in the mesos docs.</a></div>
</blockquote>
<p>The rest is up to you and how you want to work with a dockerized airflow configuration.</p>
</div>
</body>
</html>