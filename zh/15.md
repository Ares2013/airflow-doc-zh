# 使用Mesos扩展（社区贡献）

有两种方法可以将气流作为mesos框架运行：

1.  直接在mesos从站上运行气流任务，要求每个mesos从站安装和配置气流。
2.  在安装了气流的docker容器内运行气流任务，该容器在mesos slave上运行。

## 任务直接在mesos从站上执行

`MesosExecutor`允许您在Mesos群集上安排气流任务。 为此，您需要一个正在运行的mesos集群，并且必须执行以下步骤 -

1.  在将运行Web服务器和调度程序的mesos从站上安装气流，让我们将其称为“Airflow服务器”。
2.  在Airflow服务器上，从[mesos下载](http://open.mesosphere.com/downloads/mesos/)安装mesos python eggs。
3.  在Airflow服务器上，使用可从所有mesos从站访问的数据库（例如mysql）并在`airflow.cfg`添加配置。
4.  将`airflow.cfg`更改为指向`airflow.cfg`的point executor参数，并提供相关的Mesos设置。
5.  在所有mesos奴隶上，安装气流。 从Airflow服务器复制`airflow.cfg` （以便它使用相同的sql炼金术连接）。
6.  在所有mesos从服务器上，运行以下服务日志：

```
airflow serve_logs

```

1.  在Airflow服务器上，要开始在mesos上处理/调度DAG，请运行：

```
airflow scheduler -p

```

注意：我们需要-p参数来挑选DAG。

您现在可以在mesos UI中查看气流框架和相应的任务。 气流任务的日志可以像往常一样在气流UI中查看。

有关mesos的更多信息，请参阅[mesos文档](http://mesos.apache.org/documentation/latest/) 。 有关&lt;cite&gt;MesosExecutor的&lt;/cite&gt;任何疑问/错误，请联系[@ kapil-malik](https://github.com/kapil-malik) 。

## 在mesos从站上的容器中执行的任务

[此要点](https://gist.github.com/sebradloff/f158874e615bda0005c6f4577b20036e)包含实现以下所需的所有文件和配置更改：

1.  使用安装了mesos python鸡蛋创建一个dockerized版本的气流。

> 我们建议利用docker的多阶段构建来实现这一目标。 我们有一个Dockerfile定义从源（Dockerfile-mesos）构建特定版本的mesos，以便创建python egg。 在气流Dockerfile（Dockerfile-airflow）中，我们从mesos图像中复制python eggs。

1.  在`airflow.cfg`创建一个mesos配置块。

> 配置块保持与默认气流配置（default_airflow.cfg）相同，但添加了一个选项`docker_image_slave` 。 这应该设置为您希望mesos在运行气流任务时使用的图像的名称。 确保您具有适用于您的mesos主服务器的DNS记录的正确配置以及任何类型的授权（如果存在）。

1.  更改`airflow.cfg`以将执行程序参数指向&lt;cite&gt;MesosExecutor&lt;/cite&gt; （ &lt;cite&gt;executor = SequentialExecutor&lt;/cite&gt; ）。
2.  确保您的mesos slave可以访问您用于`docker_image_slave`存储库。

> [mesos文档中提供了相关说明。](https://mesos.readthedocs.io/en/latest/docker-containerizer/)

其余部分取决于您以及您希望如何使用dockerized气流配置。